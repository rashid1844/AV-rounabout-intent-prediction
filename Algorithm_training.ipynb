{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4ed6d55a490b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31866, 11)\n",
      "(31866, 1)\n",
      "zeros 5788\n",
      "ones 26078\n",
      "north 13661\n",
      "south 12005\n",
      "east 0\n",
      "west 6200\n"
     ]
    }
   ],
   "source": [
    "#X = pd.read_csv('Data_25_-2.0_-2.0_6.0.csv').values\n",
    "#y = pd.read_csv('Data_25_-2.0_-2.0_6.0_y.csv').values\n",
    "X = pd.read_csv('preprocessed_data/Data_25_2.0_-1.0_1.0.csv').values\n",
    "y = pd.read_csv('preprocessed_data/Data_25_2.0_-1.0_1.0_y.csv').values\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print('zeros', np.count_nonzero(y == 0))\n",
    "print('ones', np.count_nonzero(y == 1))\n",
    "print('north', np.count_nonzero(X[:,7] == 1))\n",
    "print('south', np.count_nonzero(X[:,8] == 1))\n",
    "print('east', np.count_nonzero(X[:,9] == 1))\n",
    "print('west', np.count_nonzero(X[:,10] == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25492 samples, validate on 6374 samples\n",
      "Epoch 1/100\n",
      "25492/25492 [==============================] - 1s 52us/sample - loss: 0.3958 - accuracy: 0.3986 - val_loss: 0.1192 - val_accuracy: 0.8549\n",
      "Epoch 2/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.1218 - accuracy: 0.8536 - val_loss: 0.1186 - val_accuracy: 0.8605\n",
      "Epoch 3/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.1084 - accuracy: 0.8678 - val_loss: 0.0822 - val_accuracy: 0.8839\n",
      "Epoch 4/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0687 - accuracy: 0.9020 - val_loss: 0.0641 - val_accuracy: 0.9167\n",
      "Epoch 5/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0658 - accuracy: 0.9082 - val_loss: 0.0521 - val_accuracy: 0.9270\n",
      "Epoch 6/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0572 - accuracy: 0.9189 - val_loss: 0.0529 - val_accuracy: 0.9233\n",
      "Epoch 7/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0530 - accuracy: 0.9263 - val_loss: 0.0478 - val_accuracy: 0.9349\n",
      "Epoch 8/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0516 - accuracy: 0.9285 - val_loss: 0.0460 - val_accuracy: 0.9377\n",
      "Epoch 9/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0493 - accuracy: 0.9315 - val_loss: 0.0450 - val_accuracy: 0.9393\n",
      "Epoch 10/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0481 - accuracy: 0.9340 - val_loss: 0.0441 - val_accuracy: 0.9398\n",
      "Epoch 11/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0473 - accuracy: 0.9343 - val_loss: 0.0440 - val_accuracy: 0.9391\n",
      "Epoch 12/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0466 - accuracy: 0.9353 - val_loss: 0.0432 - val_accuracy: 0.9405\n",
      "Epoch 13/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0461 - accuracy: 0.9355 - val_loss: 0.0431 - val_accuracy: 0.9398\n",
      "Epoch 14/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0456 - accuracy: 0.9368 - val_loss: 0.0426 - val_accuracy: 0.9409\n",
      "Epoch 15/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0453 - accuracy: 0.9367 - val_loss: 0.0426 - val_accuracy: 0.9398\n",
      "Epoch 16/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0450 - accuracy: 0.9374 - val_loss: 0.0422 - val_accuracy: 0.9418\n",
      "Epoch 17/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0448 - accuracy: 0.9374 - val_loss: 0.0421 - val_accuracy: 0.9404\n",
      "Epoch 18/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0446 - accuracy: 0.9375 - val_loss: 0.0421 - val_accuracy: 0.9401\n",
      "Epoch 19/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0445 - accuracy: 0.9381 - val_loss: 0.0419 - val_accuracy: 0.9410\n",
      "Epoch 20/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0444 - accuracy: 0.9383 - val_loss: 0.0424 - val_accuracy: 0.9401\n",
      "Epoch 21/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0446 - accuracy: 0.9372 - val_loss: 0.0416 - val_accuracy: 0.9409\n",
      "Epoch 22/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0441 - accuracy: 0.9387 - val_loss: 0.0417 - val_accuracy: 0.9401\n",
      "Epoch 23/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0441 - accuracy: 0.9385 - val_loss: 0.0415 - val_accuracy: 0.9409\n",
      "Epoch 24/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0441 - accuracy: 0.9388 - val_loss: 0.0413 - val_accuracy: 0.9426\n",
      "Epoch 25/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0439 - accuracy: 0.9390 - val_loss: 0.0413 - val_accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0437 - accuracy: 0.9392 - val_loss: 0.0411 - val_accuracy: 0.9416\n",
      "Epoch 27/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0436 - accuracy: 0.9395 - val_loss: 0.0411 - val_accuracy: 0.9416\n",
      "Epoch 28/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0436 - accuracy: 0.9395 - val_loss: 0.0414 - val_accuracy: 0.9416\n",
      "Epoch 29/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0437 - accuracy: 0.9394 - val_loss: 0.0412 - val_accuracy: 0.9432\n",
      "Epoch 30/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0440 - accuracy: 0.9395 - val_loss: 0.0416 - val_accuracy: 0.9415\n",
      "Epoch 31/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0436 - accuracy: 0.9394 - val_loss: 0.0410 - val_accuracy: 0.9432\n",
      "Epoch 32/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0435 - accuracy: 0.9398 - val_loss: 0.0418 - val_accuracy: 0.9410\n",
      "Epoch 33/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0436 - accuracy: 0.9393 - val_loss: 0.0408 - val_accuracy: 0.9435\n",
      "Epoch 34/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0434 - accuracy: 0.9398 - val_loss: 0.0407 - val_accuracy: 0.9418\n",
      "Epoch 35/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0435 - accuracy: 0.9397 - val_loss: 0.0406 - val_accuracy: 0.9424\n",
      "Epoch 36/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0430 - accuracy: 0.9406 - val_loss: 0.0406 - val_accuracy: 0.9429\n",
      "Epoch 37/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0429 - accuracy: 0.9407 - val_loss: 0.0405 - val_accuracy: 0.9437\n",
      "Epoch 38/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0429 - accuracy: 0.9406 - val_loss: 0.0409 - val_accuracy: 0.9432\n",
      "Epoch 39/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0430 - accuracy: 0.9406 - val_loss: 0.0404 - val_accuracy: 0.9421\n",
      "Epoch 40/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0427 - accuracy: 0.9412 - val_loss: 0.0405 - val_accuracy: 0.9434\n",
      "Epoch 41/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0426 - accuracy: 0.9413 - val_loss: 0.0402 - val_accuracy: 0.9440\n",
      "Epoch 42/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0426 - accuracy: 0.9412 - val_loss: 0.0404 - val_accuracy: 0.9435\n",
      "Epoch 43/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0425 - accuracy: 0.9415 - val_loss: 0.0402 - val_accuracy: 0.9445\n",
      "Epoch 44/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0425 - accuracy: 0.9412 - val_loss: 0.0401 - val_accuracy: 0.9452\n",
      "Epoch 45/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0426 - accuracy: 0.9412 - val_loss: 0.0403 - val_accuracy: 0.9430\n",
      "Epoch 46/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0423 - accuracy: 0.9412 - val_loss: 0.0400 - val_accuracy: 0.9445\n",
      "Epoch 47/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0423 - accuracy: 0.9412 - val_loss: 0.0403 - val_accuracy: 0.9434\n",
      "Epoch 48/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0423 - accuracy: 0.9408 - val_loss: 0.0401 - val_accuracy: 0.9438\n",
      "Epoch 49/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0423 - accuracy: 0.9415 - val_loss: 0.0399 - val_accuracy: 0.9449\n",
      "Epoch 50/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0422 - accuracy: 0.9410 - val_loss: 0.0406 - val_accuracy: 0.9430\n",
      "Epoch 51/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0421 - accuracy: 0.9413 - val_loss: 0.0398 - val_accuracy: 0.9449\n",
      "Epoch 52/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0420 - accuracy: 0.9415 - val_loss: 0.0399 - val_accuracy: 0.9446\n",
      "Epoch 53/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0420 - accuracy: 0.9422 - val_loss: 0.0400 - val_accuracy: 0.9437\n",
      "Epoch 54/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0418 - accuracy: 0.9425 - val_loss: 0.0398 - val_accuracy: 0.9446\n",
      "Epoch 55/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0420 - accuracy: 0.9421 - val_loss: 0.0405 - val_accuracy: 0.9423\n",
      "Epoch 56/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0418 - accuracy: 0.9422 - val_loss: 0.0396 - val_accuracy: 0.9459\n",
      "Epoch 57/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0417 - accuracy: 0.9425 - val_loss: 0.0396 - val_accuracy: 0.9454\n",
      "Epoch 58/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0415 - accuracy: 0.9424 - val_loss: 0.0395 - val_accuracy: 0.9468\n",
      "Epoch 59/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0415 - accuracy: 0.9430 - val_loss: 0.0397 - val_accuracy: 0.9446\n",
      "Epoch 60/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0414 - accuracy: 0.9431 - val_loss: 0.0396 - val_accuracy: 0.9451\n",
      "Epoch 61/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0413 - accuracy: 0.9429 - val_loss: 0.0399 - val_accuracy: 0.9446\n",
      "Epoch 62/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0414 - accuracy: 0.9428 - val_loss: 0.0393 - val_accuracy: 0.9462\n",
      "Epoch 63/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0414 - accuracy: 0.9424 - val_loss: 0.0394 - val_accuracy: 0.9446\n",
      "Epoch 64/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0413 - accuracy: 0.9434 - val_loss: 0.0393 - val_accuracy: 0.9468\n",
      "Epoch 65/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0411 - accuracy: 0.9439 - val_loss: 0.0392 - val_accuracy: 0.9463\n",
      "Epoch 66/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0411 - accuracy: 0.9442 - val_loss: 0.0399 - val_accuracy: 0.9441\n",
      "Epoch 67/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0411 - accuracy: 0.9428 - val_loss: 0.0393 - val_accuracy: 0.9452\n",
      "Epoch 68/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0410 - accuracy: 0.9435 - val_loss: 0.0390 - val_accuracy: 0.9473\n",
      "Epoch 69/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0408 - accuracy: 0.9442 - val_loss: 0.0391 - val_accuracy: 0.9465\n",
      "Epoch 70/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0407 - accuracy: 0.9443 - val_loss: 0.0389 - val_accuracy: 0.9470\n",
      "Epoch 71/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0406 - accuracy: 0.9442 - val_loss: 0.0391 - val_accuracy: 0.9459\n",
      "Epoch 72/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0406 - accuracy: 0.9442 - val_loss: 0.0390 - val_accuracy: 0.9456\n",
      "Epoch 73/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0405 - accuracy: 0.9443 - val_loss: 0.0391 - val_accuracy: 0.9451\n",
      "Epoch 74/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0407 - accuracy: 0.9443 - val_loss: 0.0393 - val_accuracy: 0.9441\n",
      "Epoch 75/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0409 - accuracy: 0.9447 - val_loss: 0.0388 - val_accuracy: 0.9478\n",
      "Epoch 76/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0404 - accuracy: 0.9450 - val_loss: 0.0387 - val_accuracy: 0.9462\n",
      "Epoch 77/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0402 - accuracy: 0.9447 - val_loss: 0.0395 - val_accuracy: 0.9449\n",
      "Epoch 78/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0406 - accuracy: 0.9441 - val_loss: 0.0385 - val_accuracy: 0.9468\n",
      "Epoch 79/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0402 - accuracy: 0.9445 - val_loss: 0.0386 - val_accuracy: 0.9454\n",
      "Epoch 80/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0406 - accuracy: 0.9441 - val_loss: 0.0386 - val_accuracy: 0.9462\n",
      "Epoch 81/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0404 - accuracy: 0.9451 - val_loss: 0.0407 - val_accuracy: 0.9437\n",
      "Epoch 82/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0404 - accuracy: 0.9452 - val_loss: 0.0384 - val_accuracy: 0.9465\n",
      "Epoch 83/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0400 - accuracy: 0.9456 - val_loss: 0.0386 - val_accuracy: 0.9452\n",
      "Epoch 84/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0401 - accuracy: 0.9459 - val_loss: 0.0382 - val_accuracy: 0.9473\n",
      "Epoch 85/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0399 - accuracy: 0.9454 - val_loss: 0.0412 - val_accuracy: 0.9424\n",
      "Epoch 86/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0408 - accuracy: 0.9443 - val_loss: 0.0383 - val_accuracy: 0.9473\n",
      "Epoch 87/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0401 - accuracy: 0.9457 - val_loss: 0.0396 - val_accuracy: 0.9437\n",
      "Epoch 88/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0405 - accuracy: 0.9443 - val_loss: 0.0390 - val_accuracy: 0.9471\n",
      "Epoch 89/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0396 - accuracy: 0.9464 - val_loss: 0.0383 - val_accuracy: 0.9467\n",
      "Epoch 90/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0394 - accuracy: 0.9460 - val_loss: 0.0383 - val_accuracy: 0.9470\n",
      "Epoch 91/100\n",
      "25492/25492 [==============================] - 0s 5us/sample - loss: 0.0395 - accuracy: 0.9464 - val_loss: 0.0384 - val_accuracy: 0.9449\n",
      "Epoch 92/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0395 - accuracy: 0.9457 - val_loss: 0.0381 - val_accuracy: 0.9478\n",
      "Epoch 93/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0395 - accuracy: 0.9460 - val_loss: 0.0389 - val_accuracy: 0.9473\n",
      "Epoch 94/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0395 - accuracy: 0.9464 - val_loss: 0.0413 - val_accuracy: 0.9427\n",
      "Epoch 95/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0409 - accuracy: 0.9428 - val_loss: 0.0384 - val_accuracy: 0.9449\n",
      "Epoch 96/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0396 - accuracy: 0.9462 - val_loss: 0.0384 - val_accuracy: 0.9457\n",
      "Epoch 97/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0401 - accuracy: 0.9452 - val_loss: 0.0399 - val_accuracy: 0.9443\n",
      "Epoch 98/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0397 - accuracy: 0.9461 - val_loss: 0.0382 - val_accuracy: 0.9479\n",
      "Epoch 99/100\n",
      "25492/25492 [==============================] - 0s 1us/sample - loss: 0.0395 - accuracy: 0.9470 - val_loss: 0.0384 - val_accuracy: 0.9451\n",
      "Epoch 100/100\n",
      "25492/25492 [==============================] - 0s 2us/sample - loss: 0.0398 - accuracy: 0.9459 - val_loss: 0.0382 - val_accuracy: 0.9457\n",
      "Test loss: 0.03818371917632799\n",
      "Test accuracy: 0.945717\n",
      "Time 5.731423854827881\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=11),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "batch_size = 5000\n",
    "epochs = 100\n",
    "s_time= time.time()\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#X_train_sub = X_train[:, 6:]\n",
    "#X_test_sub = X_test[:, 6:]\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Time', time.time()-s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36777 samples, validate on 9195 samples\n",
      "Epoch 1/50\n",
      "36777/36777 [==============================] - 1s 18us/sample - loss: 0.1775 - accuracy: 0.7581 - val_loss: 0.1032 - val_accuracy: 0.8895\n",
      "Epoch 2/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0920 - accuracy: 0.8962 - val_loss: 0.0762 - val_accuracy: 0.9143\n",
      "Epoch 3/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0667 - accuracy: 0.9217 - val_loss: 0.0532 - val_accuracy: 0.9485\n",
      "Epoch 4/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0486 - accuracy: 0.9541 - val_loss: 0.0407 - val_accuracy: 0.9610\n",
      "Epoch 5/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0390 - accuracy: 0.9590 - val_loss: 0.0344 - val_accuracy: 0.9638\n",
      "Epoch 6/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0337 - accuracy: 0.9620 - val_loss: 0.0310 - val_accuracy: 0.9651\n",
      "Epoch 7/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0310 - accuracy: 0.9624 - val_loss: 0.0289 - val_accuracy: 0.9659\n",
      "Epoch 8/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0292 - accuracy: 0.9637 - val_loss: 0.0274 - val_accuracy: 0.9665\n",
      "Epoch 9/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0279 - accuracy: 0.9643 - val_loss: 0.0262 - val_accuracy: 0.9670\n",
      "Epoch 10/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0268 - accuracy: 0.9657 - val_loss: 0.0253 - val_accuracy: 0.9677\n",
      "Epoch 11/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0259 - accuracy: 0.9664 - val_loss: 0.0245 - val_accuracy: 0.9692\n",
      "Epoch 12/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0252 - accuracy: 0.9670 - val_loss: 0.0239 - val_accuracy: 0.9701\n",
      "Epoch 13/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0247 - accuracy: 0.9673 - val_loss: 0.0233 - val_accuracy: 0.9704\n",
      "Epoch 14/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0241 - accuracy: 0.9680 - val_loss: 0.0228 - val_accuracy: 0.9705\n",
      "Epoch 15/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0236 - accuracy: 0.9686 - val_loss: 0.0225 - val_accuracy: 0.9719\n",
      "Epoch 16/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0231 - accuracy: 0.9688 - val_loss: 0.0220 - val_accuracy: 0.9721\n",
      "Epoch 17/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0227 - accuracy: 0.9694 - val_loss: 0.0218 - val_accuracy: 0.9726\n",
      "Epoch 18/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0224 - accuracy: 0.9701 - val_loss: 0.0214 - val_accuracy: 0.9730\n",
      "Epoch 19/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0220 - accuracy: 0.9704 - val_loss: 0.0211 - val_accuracy: 0.9731\n",
      "Epoch 20/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0217 - accuracy: 0.9709 - val_loss: 0.0209 - val_accuracy: 0.9734\n",
      "Epoch 21/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0214 - accuracy: 0.9711 - val_loss: 0.0205 - val_accuracy: 0.9735\n",
      "Epoch 22/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0212 - accuracy: 0.9718 - val_loss: 0.0203 - val_accuracy: 0.9740\n",
      "Epoch 23/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0208 - accuracy: 0.9719 - val_loss: 0.0201 - val_accuracy: 0.9746\n",
      "Epoch 24/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0206 - accuracy: 0.9722 - val_loss: 0.0199 - val_accuracy: 0.9739\n",
      "Epoch 25/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0203 - accuracy: 0.9727 - val_loss: 0.0196 - val_accuracy: 0.9759\n",
      "Epoch 26/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0201 - accuracy: 0.9728 - val_loss: 0.0194 - val_accuracy: 0.9741\n",
      "Epoch 27/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0199 - accuracy: 0.9732 - val_loss: 0.0192 - val_accuracy: 0.9750\n",
      "Epoch 28/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0196 - accuracy: 0.9734 - val_loss: 0.0190 - val_accuracy: 0.9751\n",
      "Epoch 29/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0194 - accuracy: 0.9739 - val_loss: 0.0189 - val_accuracy: 0.9757\n",
      "Epoch 30/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0193 - accuracy: 0.9735 - val_loss: 0.0190 - val_accuracy: 0.9761\n",
      "Epoch 31/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0192 - accuracy: 0.9740 - val_loss: 0.0185 - val_accuracy: 0.9757\n",
      "Epoch 32/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0190 - accuracy: 0.9745 - val_loss: 0.0186 - val_accuracy: 0.9761\n",
      "Epoch 33/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0188 - accuracy: 0.9748 - val_loss: 0.0190 - val_accuracy: 0.9752\n",
      "Epoch 34/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0190 - accuracy: 0.9744 - val_loss: 0.0181 - val_accuracy: 0.9760\n",
      "Epoch 35/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0184 - accuracy: 0.9743 - val_loss: 0.0179 - val_accuracy: 0.9760\n",
      "Epoch 36/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0182 - accuracy: 0.9756 - val_loss: 0.0179 - val_accuracy: 0.9763\n",
      "Epoch 37/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0181 - accuracy: 0.9753 - val_loss: 0.0177 - val_accuracy: 0.9766\n",
      "Epoch 38/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0179 - accuracy: 0.9758 - val_loss: 0.0177 - val_accuracy: 0.9767\n",
      "Epoch 39/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0177 - accuracy: 0.9757 - val_loss: 0.0174 - val_accuracy: 0.9775\n",
      "Epoch 40/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0175 - accuracy: 0.9759 - val_loss: 0.0173 - val_accuracy: 0.9769\n",
      "Epoch 41/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0174 - accuracy: 0.9766 - val_loss: 0.0176 - val_accuracy: 0.9774\n",
      "Epoch 42/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0176 - accuracy: 0.9763 - val_loss: 0.0170 - val_accuracy: 0.9775\n",
      "Epoch 43/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0172 - accuracy: 0.9771 - val_loss: 0.0168 - val_accuracy: 0.9779\n",
      "Epoch 44/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0170 - accuracy: 0.9770 - val_loss: 0.0171 - val_accuracy: 0.9784\n",
      "Epoch 45/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0171 - accuracy: 0.9765 - val_loss: 0.0167 - val_accuracy: 0.9784\n",
      "Epoch 46/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0168 - accuracy: 0.9778 - val_loss: 0.0166 - val_accuracy: 0.9784\n",
      "Epoch 47/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0167 - accuracy: 0.9776 - val_loss: 0.0163 - val_accuracy: 0.9786\n",
      "Epoch 48/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0165 - accuracy: 0.9779 - val_loss: 0.0162 - val_accuracy: 0.9788\n",
      "Epoch 49/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0164 - accuracy: 0.9779 - val_loss: 0.0161 - val_accuracy: 0.9799\n",
      "Epoch 50/50\n",
      "36777/36777 [==============================] - 0s 1us/sample - loss: 0.0162 - accuracy: 0.9780 - val_loss: 0.0161 - val_accuracy: 0.9788\n",
      "Test loss: 0.0160978658137212\n",
      "Test accuracy: 0.97879285\n",
      "Time 3.3261444568634033\n"
     ]
    }
   ],
   "source": [
    "# using speed and origin only\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=6),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "batch_size = 5000\n",
    "epochs = 50\n",
    "s_time= time.time()\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_train_sub = X_train[:, :6]\n",
    "X_test_sub = X_test[:, :6]\n",
    "\n",
    "history = model.fit(X_train_sub, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test_sub, y_test))\n",
    "\n",
    "score = model.evaluate(X_test_sub, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Time', time.time()-s_time)\n",
    "model.save('models/model_-2_6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 0.9997602\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "model1 = load_model('models/model_-2_6.h5')\n",
    "x1 = np.array([[0,2,3,0,5,6]])\n",
    "o=model1.predict(x1)\n",
    "print('predict',o[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [0.00184283]\n",
      "[1] [0.99999946]\n",
      "[0] [2.115965e-06]\n",
      "[0] [1.2516975e-06]\n",
      "[0] [0.00027665]\n",
      "[0] [0.]\n",
      "[1] [0.9998117]\n",
      "[0] [2.7120113e-06]\n",
      "[1] [0.999998]\n",
      "[0] [1.9073486e-06]\n",
      "[0] [3.3825636e-05]\n",
      "[0] [2.2143126e-05]\n",
      "[0] [9.268522e-06]\n",
      "[1] [0.9999868]\n",
      "[1] [0.99999976]\n",
      "[0] [7.1525574e-07]\n",
      "[0] [0.]\n",
      "[0] [5.9604645e-08]\n",
      "[0] [6.467104e-06]\n",
      "[0] [3.993511e-06]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [1.013279e-06]\n",
      "[0] [8.940697e-08]\n",
      "[1] [0.99999905]\n",
      "[0] [1.1920929e-07]\n",
      "[0] [0.]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [3.0398369e-06]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[1] [0.99999976]\n",
      "[1] [0.99999976]\n",
      "[0] [3.2782555e-07]\n",
      "[0] [8.60095e-05]\n",
      "[1] [0.9999998]\n",
      "[0] [0.]\n",
      "[1] [0.9999974]\n",
      "[1] [0.99999547]\n",
      "[0] [0.]\n",
      "[0] [4.9322844e-05]\n",
      "[1] [0.9999979]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [1.013279e-06]\n",
      "[1] [0.9999983]\n",
      "[1] [0.9999999]\n",
      "[0] [1.1920929e-07]\n",
      "[0] [5.6028366e-06]\n",
      "[0] [0.00010598]\n",
      "[0] [1.4901161e-06]\n",
      "[0] [1.8715858e-05]\n",
      "[0] [0.00036451]\n",
      "[1] [0.99999976]\n",
      "[1] [0.99999976]\n",
      "[0] [1.6361475e-05]\n",
      "[0] [7.122755e-06]\n",
      "[1] [0.99999946]\n",
      "[1] [0.9999999]\n",
      "[0] [0.00021872]\n",
      "[0] [0.00815344]\n",
      "[1] [0.9999999]\n",
      "[1] [0.9999999]\n",
      "[0] [1.7881393e-07]\n",
      "[1] [0.99405634]\n",
      "[0] [0.]\n",
      "[1] [0.0775511]\n",
      "[1] [0.9999994]\n",
      "[0] [0.]\n",
      "[0] [3.0398369e-05]\n",
      "[1] [0.99999744]\n",
      "[0] [1.5169382e-05]\n",
      "[1] [0.9999995]\n",
      "[0] [7.122755e-05]\n",
      "[0] [9.62615e-06]\n",
      "[1] [0.99999994]\n",
      "[1] [0.9999986]\n",
      "[0] [2.0861626e-07]\n",
      "[0] [0.00038379]\n",
      "[0] [0.00033537]\n",
      "[1] [0.99999976]\n",
      "[0] [2.0861626e-06]\n",
      "[1] [0.9999993]\n",
      "[0] [0.00049138]\n",
      "[1] [1.]\n",
      "[0] [0.]\n",
      "[0] [4.529953e-06]\n",
      "[0] [0.00012884]\n",
      "[1] [0.9999987]\n",
      "[0] [6.467104e-06]\n",
      "[1] [0.99999964]\n",
      "[0] [0.]\n",
      "[0] [1.32620335e-05]\n",
      "[0] [1.4901161e-06]\n",
      "[1] [0.9999999]\n",
      "[0] [5.9604645e-08]\n",
      "[0] [1.7881393e-07]\n",
      "[0] [2.9802322e-08]\n",
      "[1] [0.99999946]\n",
      "[0] [4.6491623e-06]\n",
      "[0] [8.6426735e-07]\n",
      "[1] [0.9999999]\n",
      "[0] [5.3048134e-06]\n",
      "[0] [0.]\n",
      "[0] [0.00011161]\n",
      "[0] [4.261732e-06]\n",
      "[0] [0.]\n",
      "[0] [9.459257e-05]\n",
      "[0] [1.4603138e-06]\n",
      "[0] [0.]\n",
      "[0] [8.940697e-08]\n",
      "[0] [1.3113022e-06]\n",
      "[1] [1.]\n",
      "[0] [1.4901161e-07]\n",
      "[1] [0.99999964]\n",
      "[0] [0.0014239]\n",
      "[0] [0.00035858]\n",
      "[0] [0.]\n",
      "[1] [0.99999595]\n",
      "[0] [0.]\n",
      "[1] [0.9999648]\n",
      "[0] [1.1622906e-06]\n",
      "[0] [3.1590462e-06]\n",
      "[0] [0.00032699]\n",
      "[0] [7.364154e-05]\n",
      "[0] [0.00087652]\n",
      "[1] [0.99999654]\n",
      "[0] [5.364418e-07]\n",
      "[0] [7.212162e-06]\n",
      "[0] [0.3150056]\n",
      "[0] [1.4901161e-07]\n",
      "[1] [0.99999994]\n",
      "[0] [1.1920929e-07]\n",
      "[1] [0.9839187]\n",
      "[1] [1.]\n",
      "[0] [0.0089851]\n",
      "[0] [0.00013304]\n",
      "[0] [1.6093254e-06]\n",
      "[1] [0.99999994]\n",
      "[0] [0.]\n",
      "[1] [0.99957407]\n",
      "[0] [4.506111e-05]\n",
      "[1] [0.99999744]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [1.4901161e-06]\n",
      "[0] [1.8328428e-05]\n",
      "[1] [1.]\n",
      "[1] [0.9999999]\n",
      "[1] [0.99999994]\n",
      "[0] [1.4007092e-06]\n",
      "[0] [1.1920929e-07]\n",
      "[0] [0.00014576]\n",
      "[0] [5.9604645e-08]\n",
      "[1] [0.45694616]\n",
      "[1] [0.99999994]\n",
      "[0] [2.9116869e-05]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [0.0032506]\n",
      "[0] [4.7683716e-07]\n",
      "[0] [2.861023e-06]\n",
      "[1] [0.9999986]\n",
      "[0] [4.0501356e-05]\n",
      "[0] [5.990267e-06]\n",
      "[1] [0.9999961]\n",
      "[0] [2.682209e-07]\n",
      "[0] [2.3245811e-05]\n",
      "[1] [1.]\n",
      "[1] [0.99999976]\n",
      "[0] [0.]\n",
      "[0] [2.3841858e-07]\n",
      "[0] [4.172325e-07]\n",
      "[0] [0.00037757]\n",
      "[1] [0.9999989]\n",
      "[0] [0.]\n",
      "[0] [6.097555e-05]\n",
      "[0] [0.0049738]\n",
      "[0] [2.9802322e-08]\n",
      "[1] [0.9999869]\n",
      "[0] [0.]\n",
      "[0] [1.3709068e-06]\n",
      "[0] [9.715557e-05]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [4.7683716e-07]\n",
      "[0] [8.940697e-08]\n",
      "[1] [0.99999976]\n",
      "[0] [2.3454428e-05]\n",
      "[0] [0.]\n",
      "[0] [0.00066811]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[1] [0.9999996]\n",
      "[1] [0.9999989]\n",
      "[0] [2.488494e-05]\n",
      "[1] [0.99788904]\n",
      "[0] [0.00045133]\n",
      "[0] [0.]\n",
      "[1] [0.9999982]\n",
      "[0] [9.918213e-05]\n",
      "[0] [0.]\n",
      "[1] [0.9999982]\n",
      "[0] [1.4007092e-06]\n",
      "[0] [2.8908253e-06]\n",
      "[0] [8.5532665e-06]\n",
      "[1] [1.]\n",
      "[1] [0.99984753]\n",
      "[0] [2.0861626e-07]\n",
      "[1] [0.99999917]\n",
      "[1] [0.99999917]\n",
      "[0] [3.6001205e-05]\n",
      "[0] [5.7816505e-06]\n",
      "[1] [0.99999976]\n",
      "[0] [0.0005258]\n",
      "[1] [0.99999976]\n",
      "[1] [0.99999523]\n",
      "[0] [2.989173e-05]\n",
      "[0] [1.4901161e-07]\n",
      "[0] [3.0100346e-06]\n",
      "[0] [6.0796738e-06]\n",
      "[1] [0.99999964]\n",
      "[0] [0.]\n",
      "[1] [0.99999875]\n",
      "[0] [4.351139e-06]\n",
      "[1] [0.9999993]\n",
      "[0] [0.00043789]\n",
      "[0] [4.172325e-07]\n",
      "[0] [0.]\n",
      "[0] [2.0861626e-07]\n",
      "[0] [6.2584877e-07]\n",
      "[0] [1.4305115e-06]\n",
      "[1] [0.99999976]\n",
      "[0] [0.]\n",
      "[1] [0.9999708]\n",
      "[0] [1.4007092e-06]\n",
      "[0] [1.937151e-06]\n",
      "[0] [5.364418e-07]\n",
      "[1] [0.99937385]\n",
      "[0] [0.]\n",
      "[0] [0.]\n",
      "[0] [3.5762787e-07]\n",
      "[1] [0.99606085]\n",
      "[0] [2.6524067e-06]\n",
      "[0] [8.940697e-08]\n",
      "[1] [0.99998486]\n",
      "[0] [6.8843365e-06]\n",
      "[0] [1.1920929e-07]\n",
      "[1] [0.999998]\n",
      "[0] [0.00255135]\n",
      "[0] [0.]\n",
      "[0] [5.662441e-07]\n",
      "[0] [3.182888e-05]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [0.]\n",
      "[0] [7.748604e-07]\n",
      "[1] [0.99999964]\n",
      "[0] [4.23193e-06]\n",
      "[0] [8.940697e-08]\n",
      "[0] [0.]\n",
      "[0] [0.00188363]\n",
      "[0] [0.]\n",
      "[0] [2.4437904e-06]\n",
      "[1] [0.9999992]\n",
      "[0] [0.]\n",
      "[1] [0.99298644]\n",
      "[0] [2.9802322e-07]\n",
      "[0] [3.0875206e-05]\n",
      "[0] [1.1920929e-07]\n",
      "[1] [0.9999857]\n",
      "[1] [0.99999756]\n",
      "[0] [0.]\n",
      "[0] [3.6656857e-06]\n",
      "[0] [0.]\n",
      "[0] [0.28319973]\n",
      "[0] [0.]\n",
      "[0] [1.7881393e-07]\n",
      "[0] [2.3841858e-07]\n",
      "[0] [1.7881393e-06]\n",
      "[0] [1.8179417e-06]\n",
      "[0] [0.00032881]\n",
      "[0] [0.]\n",
      "[1] [0.9988785]\n",
      "[0] [8.940697e-08]\n",
      "[0] [1.32620335e-05]\n",
      "[1] [0.999492]\n",
      "[1] [0.99802315]\n",
      "[0] [7.084012e-05]\n",
      "[0] [0.72459537]\n",
      "[1] [0.9999989]\n",
      "[1] [0.99998516]\n",
      "[0] [3.695488e-06]\n",
      "[1] [0.9999998]\n",
      "[0] [5.9604645e-08]\n",
      "[1] [0.9909648]\n",
      "[0] [0.00010872]\n",
      "[0] [6.854534e-07]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [0.02014238]\n",
      "[0] [0.]\n",
      "[1] [0.97739923]\n",
      "[1] [0.9999999]\n",
      "[0] [2.7418137e-05]\n",
      "[0] [5.096197e-06]\n",
      "[1] [0.9999999]\n",
      "[0] [6.3180923e-06]\n",
      "[1] [1.]\n",
      "[0] [0.00022063]\n",
      "[0] [1.0788441e-05]\n",
      "[0] [2.9802322e-07]\n",
      "[0] [6.5267086e-06]\n",
      "[0] [0.01125383]\n",
      "[1] [0.9999993]\n",
      "[0] [0.]\n",
      "[0] [1.579523e-05]\n",
      "[1] [0.99999994]\n",
      "[1] [0.9999999]\n",
      "[0] [0.]\n",
      "[0] [5.364418e-07]\n",
      "[0] [1.7881393e-06]\n",
      "[0] [2.861023e-06]\n",
      "[0] [6.580353e-05]\n",
      "[1] [0.9190126]\n",
      "[0] [1.9967556e-06]\n",
      "[1] [0.9999999]\n",
      "[0] [6.2584877e-07]\n",
      "[0] [2.9802322e-07]\n",
      "[1] [0.97020066]\n",
      "[1] [1.]\n",
      "[1] [0.99999917]\n",
      "[1] [0.9999826]\n",
      "[1] [0.9995722]\n",
      "[0] [0.]\n",
      "[0] [1.937151e-06]\n",
      "[1] [0.99999964]\n",
      "[0] [3.144145e-05]\n",
      "[0] [0.]\n",
      "[0] [1.1920929e-07]\n",
      "[0] [0.00161928]\n",
      "[0] [1.0818243e-05]\n",
      "[1] [0.99661016]\n",
      "[1] [0.99999917]\n",
      "[0] [0.]\n",
      "[0] [1.66893e-05]\n",
      "[0] [2.3841858e-07]\n",
      "[0] [2.4706125e-05]\n",
      "[1] [0.99999964]\n",
      "[0] [3.2782555e-07]\n",
      "[0] [6.854534e-07]\n",
      "[0] [3.8444996e-06]\n",
      "[0] [0.]\n",
      "[0] [2.798438e-05]\n",
      "[0] [2.3841858e-07]\n",
      "[0] [1.937151e-06]\n",
      "[0] [3.1501055e-05]\n",
      "[0] [2.9802322e-08]\n",
      "[0] [8.672476e-06]\n",
      "[0] [6.824732e-06]\n",
      "[1] [0.9999999]\n",
      "[0] [1.1622906e-06]\n",
      "[1] [0.9999999]\n",
      "[0] [1.0728836e-06]\n",
      "[1] [0.9999323]\n",
      "[0] [6.2584877e-07]\n",
      "[0] [7.56979e-06]\n",
      "[0] [3.5762787e-07]\n",
      "[0] [2.9802322e-08]\n",
      "[1] [0.99885297]\n",
      "[1] [0.99999976]\n",
      "[0] [2.0861626e-07]\n",
      "[1] [0.9999999]\n",
      "[1] [0.9999981]\n",
      "[1] [0.99999785]\n"
     ]
    }
   ],
   "source": [
    "y_out=model.predict(X_test)\n",
    "for i in range(len(y_out)):\n",
    "    print(y_test[i],y_out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    errors = abs(predictions - y)\n",
    "    # Display the performance metrics\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2)**2, 'degrees.')\n",
    "    mape = np.mean(100 * (errors / len(y)))\n",
    "    accuracy = 100 - mape\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   17.9s\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, \n",
    "                               max_features = None,\n",
    "                               n_jobs=10, verbose = 1)\n",
    "s_time= time.time()\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "# Stats about the trees in random forest\n",
    "for ind_tree in model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "#train_rf_probs = model.predict_proba(X_train)[:, 1]\n",
    "test_predictions = model.predict(X_test)\n",
    "#rf_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "print('train accuracy:')\n",
    "accuracy(train_predictions, y_train)\n",
    "\n",
    "print('test accuracy:')\n",
    "accuracy(test_predictions, y_test)\n",
    "\n",
    "\n",
    "print('Time', time.time()-s_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.88627\ttrain-auc:0.87657\n",
      "[1]\teval-auc:0.94388\ttrain-auc:0.93956\n",
      "[2]\teval-auc:0.96211\ttrain-auc:0.95876\n",
      "[3]\teval-auc:0.96767\ttrain-auc:0.96410\n",
      "[4]\teval-auc:0.96984\ttrain-auc:0.96759\n",
      "[5]\teval-auc:0.97106\ttrain-auc:0.96861\n",
      "[6]\teval-auc:0.97104\ttrain-auc:0.96962\n",
      "[7]\teval-auc:0.97152\ttrain-auc:0.97012\n",
      "[8]\teval-auc:0.97214\ttrain-auc:0.97101\n",
      "[9]\teval-auc:0.97212\ttrain-auc:0.97179\n",
      "[10]\teval-auc:0.97337\ttrain-auc:0.97297\n",
      "[11]\teval-auc:0.97367\ttrain-auc:0.97344\n",
      "[12]\teval-auc:0.97416\ttrain-auc:0.97410\n",
      "[13]\teval-auc:0.97416\ttrain-auc:0.97428\n",
      "[14]\teval-auc:0.97423\ttrain-auc:0.97462\n",
      "[15]\teval-auc:0.97447\ttrain-auc:0.97481\n",
      "[16]\teval-auc:0.97446\ttrain-auc:0.97507\n",
      "[17]\teval-auc:0.97464\ttrain-auc:0.97535\n",
      "[18]\teval-auc:0.97444\ttrain-auc:0.97548\n",
      "[19]\teval-auc:0.97447\ttrain-auc:0.97581\n",
      "[20]\teval-auc:0.97451\ttrain-auc:0.97598\n",
      "[21]\teval-auc:0.97431\ttrain-auc:0.97603\n",
      "[22]\teval-auc:0.97449\ttrain-auc:0.97623\n",
      "[23]\teval-auc:0.97558\ttrain-auc:0.97675\n",
      "[24]\teval-auc:0.97558\ttrain-auc:0.97705\n",
      "[25]\teval-auc:0.97555\ttrain-auc:0.97720\n",
      "[26]\teval-auc:0.97550\ttrain-auc:0.97739\n",
      "[27]\teval-auc:0.97564\ttrain-auc:0.97759\n",
      "[28]\teval-auc:0.97530\ttrain-auc:0.97796\n",
      "[29]\teval-auc:0.97536\ttrain-auc:0.97811\n",
      "[30]\teval-auc:0.97530\ttrain-auc:0.97826\n",
      "[31]\teval-auc:0.97527\ttrain-auc:0.97841\n",
      "[32]\teval-auc:0.97517\ttrain-auc:0.97871\n",
      "[33]\teval-auc:0.97518\ttrain-auc:0.97892\n",
      "[34]\teval-auc:0.97529\ttrain-auc:0.97901\n",
      "[35]\teval-auc:0.97506\ttrain-auc:0.97919\n",
      "[36]\teval-auc:0.97504\ttrain-auc:0.97921\n",
      "[37]\teval-auc:0.97491\ttrain-auc:0.97936\n",
      "[38]\teval-auc:0.97523\ttrain-auc:0.97956\n",
      "[39]\teval-auc:0.97557\ttrain-auc:0.97973\n",
      "[40]\teval-auc:0.97557\ttrain-auc:0.97991\n",
      "[41]\teval-auc:0.97550\ttrain-auc:0.97998\n",
      "[42]\teval-auc:0.97560\ttrain-auc:0.98007\n",
      "[43]\teval-auc:0.97584\ttrain-auc:0.98022\n",
      "[44]\teval-auc:0.97583\ttrain-auc:0.98031\n",
      "[45]\teval-auc:0.97575\ttrain-auc:0.98042\n",
      "[46]\teval-auc:0.97574\ttrain-auc:0.98050\n",
      "[47]\teval-auc:0.97571\ttrain-auc:0.98059\n",
      "[48]\teval-auc:0.97564\ttrain-auc:0.98064\n",
      "[49]\teval-auc:0.97573\ttrain-auc:0.98074\n",
      "[50]\teval-auc:0.97569\ttrain-auc:0.98082\n",
      "[51]\teval-auc:0.97530\ttrain-auc:0.98101\n",
      "[52]\teval-auc:0.97534\ttrain-auc:0.98105\n",
      "[53]\teval-auc:0.97540\ttrain-auc:0.98114\n",
      "[54]\teval-auc:0.97559\ttrain-auc:0.98121\n",
      "[55]\teval-auc:0.97562\ttrain-auc:0.98130\n",
      "[56]\teval-auc:0.97582\ttrain-auc:0.98141\n",
      "[57]\teval-auc:0.97570\ttrain-auc:0.98149\n",
      "[58]\teval-auc:0.97580\ttrain-auc:0.98171\n",
      "[59]\teval-auc:0.97589\ttrain-auc:0.98177\n",
      "[60]\teval-auc:0.97601\ttrain-auc:0.98182\n",
      "[61]\teval-auc:0.97574\ttrain-auc:0.98194\n",
      "[62]\teval-auc:0.97606\ttrain-auc:0.98208\n",
      "[63]\teval-auc:0.97614\ttrain-auc:0.98215\n",
      "[64]\teval-auc:0.97628\ttrain-auc:0.98227\n",
      "[65]\teval-auc:0.97636\ttrain-auc:0.98238\n",
      "[66]\teval-auc:0.97632\ttrain-auc:0.98247\n",
      "[67]\teval-auc:0.97618\ttrain-auc:0.98253\n",
      "[68]\teval-auc:0.97613\ttrain-auc:0.98259\n",
      "[69]\teval-auc:0.97635\ttrain-auc:0.98266\n",
      "[70]\teval-auc:0.97622\ttrain-auc:0.98274\n",
      "[71]\teval-auc:0.97603\ttrain-auc:0.98281\n",
      "[72]\teval-auc:0.97589\ttrain-auc:0.98290\n",
      "[73]\teval-auc:0.97585\ttrain-auc:0.98302\n",
      "[74]\teval-auc:0.97593\ttrain-auc:0.98310\n",
      "[75]\teval-auc:0.97585\ttrain-auc:0.98315\n",
      "[76]\teval-auc:0.97584\ttrain-auc:0.98320\n",
      "[77]\teval-auc:0.97570\ttrain-auc:0.98327\n",
      "[78]\teval-auc:0.97571\ttrain-auc:0.98334\n",
      "[79]\teval-auc:0.97537\ttrain-auc:0.98341\n",
      "[80]\teval-auc:0.97530\ttrain-auc:0.98345\n",
      "[81]\teval-auc:0.97543\ttrain-auc:0.98361\n",
      "[82]\teval-auc:0.97555\ttrain-auc:0.98370\n",
      "[83]\teval-auc:0.97542\ttrain-auc:0.98376\n",
      "[84]\teval-auc:0.97545\ttrain-auc:0.98383\n",
      "[85]\teval-auc:0.97552\ttrain-auc:0.98389\n",
      "[86]\teval-auc:0.97547\ttrain-auc:0.98393\n",
      "[87]\teval-auc:0.97546\ttrain-auc:0.98395\n",
      "[88]\teval-auc:0.97550\ttrain-auc:0.98398\n",
      "[89]\teval-auc:0.97531\ttrain-auc:0.98410\n",
      "[90]\teval-auc:0.97528\ttrain-auc:0.98413\n",
      "[91]\teval-auc:0.97548\ttrain-auc:0.98415\n",
      "[92]\teval-auc:0.97544\ttrain-auc:0.98427\n",
      "[93]\teval-auc:0.97543\ttrain-auc:0.98434\n",
      "[94]\teval-auc:0.97534\ttrain-auc:0.98439\n",
      "[95]\teval-auc:0.97530\ttrain-auc:0.98444\n",
      "[96]\teval-auc:0.97522\ttrain-auc:0.98449\n",
      "[97]\teval-auc:0.97521\ttrain-auc:0.98453\n",
      "[98]\teval-auc:0.97508\ttrain-auc:0.98456\n",
      "[99]\teval-auc:0.97511\ttrain-auc:0.98459\n",
      "train accuracy:\n",
      "test accuracy:\n",
      "Time 1.8668861389160156\n"
     ]
    }
   ],
   "source": [
    "X_train_sub = X_train[:, :6]\n",
    "X_test_sub = X_test[:, :6]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_sub, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_sub, label=y_test)\n",
    "\n",
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "s_time= time.time()\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "\n",
    "ypred_train = bst.predict(dtrain)\n",
    "ypred_test = bst.predict(dtest)\n",
    "\n",
    "print('train accuracy:')\n",
    "#accuracy(ypred_train, y_train)\n",
    "pickle.dump( {'xg':bst}, open( \"models/xg_-1_1_25.p\", \"wb\" ) )\n",
    "\n",
    "print('test accuracy:')\n",
    "#accuracy(ypred_test, y_test)\n",
    "\n",
    "print('Time', time.time()-s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0054679625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.predict(xgb.DMatrix(np.array([[1,2,3,4,5,6]])))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashid\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 1.0\n",
      "test accuracy: 0.9892761394101877\n",
      "Mean Absolute Error: 0.18489999999999998 degrees.\n",
      "Accuracy: 99.88 %.\n",
      "Time 1.2909202575683594\n"
     ]
    }
   ],
   "source": [
    "s_time= time.time()\n",
    "clf = AdaBoostClassifier(n_estimators=500, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('train accuracy:', clf.score(X_train, y_train))\n",
    "\n",
    "print('test accuracy:', clf.score(X_test, y_test))\n",
    "accuracy(clf.predict(X_test), y_test)\n",
    "print('Time', time.time()-s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
